{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from shutil import copyfile\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from .csv file\n",
    "\n",
    "* `train-images-boxable.csv` file contains the image name and image url\n",
    "* `train-annotations-bbox.csv` file contains the bounding box info with the image id (name) and the image label name\n",
    "* `class-descriptions-boxable.csv` file contains the image label name corresponding to its class name\n",
    "\n",
    "Download link:\n",
    "\n",
    "https://storage.googleapis.com/openimages/web/download.html\n",
    "\n",
    "https://www.figure-eight.com/dataset/open-images-annotated-with-bounding-boxes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = 'Dataset/Open Images Dataset v4 (Bounding Boxes)'\n",
    "images_boxable_fname = 'train-images-boxable.csv'\n",
    "annotations_bbox_fname = 'train-annotations-bbox.csv'\n",
    "class_descriptions_fname = 'class-descriptions-boxable.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_boxable = pd.read_csv(os.path.join(base_path, images_boxable_fname))\n",
    "images_boxable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_bbox = pd.read_csv(os.path.join(base_path, annotations_bbox_fname))\n",
    "annotations_bbox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions = pd.read_csv(os.path.join(base_path, class_descriptions_fname))\n",
    "class_descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show one image by using these three tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of the images_boxable: %d' %(len(images_boxable)) )\n",
    "print('First image in images_boxableðŸ‘‡')\n",
    "img_name = images_boxable['image_name'][0]\n",
    "img_url = images_boxable['image_url'][0]\n",
    "print('\\t image_name: %s' % (img_name))\n",
    "print('\\t img_url: %s' % (img_url))\n",
    "print('')\n",
    "print('length of the annotations_bbox: %d' %(len(annotations_bbox)))\n",
    "print('The number of bounding boxes are larger than number of images.')\n",
    "print('')\n",
    "print('length of the class_descriptions: %d' % (len(class_descriptions)-1))\n",
    "img = io.imread(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = img.shape\n",
    "print(img.shape)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img)\n",
    "img_id = img_name[:16]\n",
    "bboxs = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "img_bbox = img.copy()\n",
    "for index, row in bboxs.iterrows():\n",
    "    xmin = row['XMin']\n",
    "    xmax = row['XMax']\n",
    "    ymin = row['YMin']\n",
    "    ymax = row['YMax']\n",
    "    xmin = int(xmin*width)\n",
    "    xmax = int(xmax*width)\n",
    "    ymin = int(ymin*height)\n",
    "    ymax = int(ymax*height)\n",
    "    label_name = row['LabelName']\n",
    "    class_series = class_descriptions[class_descriptions['name']==label_name]\n",
    "    class_name = class_series['class'].values[0]\n",
    "    cv2.rectangle(img_bbox,(xmin,ymin),(xmax,ymax),(0,255,0),2)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img_bbox,class_name,(xmin,ymin-10), font, 1,(0,255,0),2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Image with Bounding Box')\n",
    "plt.imshow(img_bbox)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# io.imsave(os.path.join(base_path,'Person')+'/1.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, by using these three tables, the image with bounding box could be drawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subset of the whole dataset\n",
    "\n",
    "For here, I just want to detect three classes, which include person, mobile phone and car.\n",
    "\n",
    "The dataset from [Open Images Dataset V4](https://storage.googleapis.com/openimages/web/download.html) is too large for me. So I just extract 1000 images for each class from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the label_name for 'Person', 'Mobile Phone' and 'Car' classes\n",
    "person_pd = class_descriptions[class_descriptions['class']=='Person']\n",
    "phone_pd = class_descriptions[class_descriptions['class']=='Mobile phone']\n",
    "car_pd = class_descriptions[class_descriptions['class']=='Car']\n",
    "\n",
    "label_name_person = person_pd['name'].values[0]\n",
    "label_name_phone = phone_pd['name'].values[0]\n",
    "label_name_car = car_pd['name'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(person_pd)\n",
    "print(phone_pd)\n",
    "print(car_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful that there might be several object in one image. For example, there are three person and two mobile phone in one image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person_bbox = annotations_bbox[annotations_bbox['LabelName']==label_name_person]\n",
    "phone_bbox = annotations_bbox[annotations_bbox['LabelName']==label_name_phone]\n",
    "car_bbox = annotations_bbox[annotations_bbox['LabelName']==label_name_car]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are %d persons in the dataset' %(len(person_bbox)))\n",
    "print('There are %d phones in the dataset' %(len(phone_bbox)))\n",
    "print('There are %d cars in the dataset' %(len(car_bbox)))\n",
    "person_img_id = person_bbox['ImageID']\n",
    "phone_img_id = phone_bbox['ImageID']\n",
    "car_img_id = car_bbox['ImageID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_img_id = np.unique(person_img_id)\n",
    "phone_img_id = np.unique(phone_img_id)\n",
    "car_img_id = np.unique(car_img_id)\n",
    "print('There are %d images which contain persons' % (len(person_img_id)))\n",
    "print('There are %d images which contain phones' % (len(phone_img_id)))\n",
    "print('There are %d images which contain cars' % (len(car_img_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just randomly pick 1000 images in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the ids and pick the first 1000 ids\n",
    "copy_person_id = person_img_id.copy()\n",
    "random.seed(1)\n",
    "random.shuffle(copy_person_id)\n",
    "\n",
    "copy_phone_id = phone_img_id.copy()\n",
    "random.seed(1)\n",
    "random.shuffle(copy_phone_id)\n",
    "\n",
    "copy_car_id = car_img_id.copy()\n",
    "random.seed(1)\n",
    "random.shuffle(copy_car_id)\n",
    "\n",
    "n = 1000\n",
    "subperson_img_id = copy_person_id[:n]\n",
    "subphone_img_id = copy_phone_id[:n]\n",
    "subcar_img_id = copy_car_id[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subperson_img_id[10])\n",
    "print(subphone_img_id[10])\n",
    "print(subcar_img_id[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This might takes a while to search all these urls\n",
    "subperson_img_url = [images_boxable[images_boxable['image_name']==name+'.jpg'] for name in subperson_img_id]\n",
    "subphone_img_url = [images_boxable[images_boxable['image_name']==name+'.jpg'] for name in subphone_img_id]\n",
    "subcar_img_url = [images_boxable[images_boxable['image_name']==name+'.jpg'] for name in subcar_img_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subperson_pd = pd.DataFrame()\n",
    "subphone_pd = pd.DataFrame()\n",
    "subcar_pd = pd.DataFrame()\n",
    "for i in range(len(subperson_img_url)):\n",
    "    subperson_pd = subperson_pd.append(subperson_img_url[i], ignore_index = True)\n",
    "    subphone_pd = subphone_pd.append(subphone_img_url[i], ignore_index = True)\n",
    "    subcar_pd = subcar_pd.append(subcar_img_url[i], ignore_index = True)\n",
    "subperson_pd.to_csv(os.path.join(base_path, 'subperson_img_url.csv'))\n",
    "subphone_pd.to_csv(os.path.join(base_path, 'subphone_img_url.csv'))\n",
    "subcar_pd.to_csv(os.path.join(base_path, 'subcar_img_url.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subperson_img_url = [url['image_url'].values[0] for url in subperson_img_url]\n",
    "subphone_img_url = [url['image_url'].values[0] for url in subphone_img_url]\n",
    "subcar_img_url = [url['image_url'].values[0] for url in subcar_img_url]\n",
    "urls = [subperson_img_url, subphone_img_url, subcar_img_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subperson_pd = pd.read_csv('Dataset/Open Images Dataset v4 (Bounding Boxes)/subperson_img_url.csv')\n",
    "subphone_pd = pd.read_csv('Dataset/Open Images Dataset v4 (Bounding Boxes)/subphone_img_url.csv')\n",
    "subcar_pd = pd.read_csv('Dataset/Open Images Dataset v4 (Bounding Boxes)/subcar_img_url.csv')\n",
    "\n",
    "subperson_img_url = subperson_pd['image_url'].values\n",
    "subphone_img_url = subphone_pd['image_url'].values\n",
    "subcar_img_url = subcar_pd['image_url'].values\n",
    "\n",
    "urls = [subperson_img_url, subphone_img_url, subcar_img_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0][743]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_dirs = [os.path.join(base_path,'Person'),os.path.join(base_path,'Mobile phone'),os.path.join(base_path,'Car')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['Person', 'Mobile phone', 'Car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urls[0]))\n",
    "print(urls[0][0])\n",
    "print(saved_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download images\n",
    "for i in range(len(classes)):\n",
    "    # Create the directory\n",
    "    os.mkdir(saved_dirs[i])\n",
    "    saved_dir = saved_dirs[i]\n",
    "    for url in urls[i]:\n",
    "        # print(url)\n",
    "        img = io.imread(url)\n",
    "        saved_path = os.path.join(saved_dir, url[-20:])\n",
    "        io.imsave(saved_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset format for faster rcnn code\n",
    "\n",
    "(fname_path, xmin, xmax, ymin, ymax, class_name)\n",
    "\n",
    "train: 0.8\n",
    "validation: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save images to train and test directory\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "os.mkdir(train_path)\n",
    "test_path = os.path.join(base_path, 'test')\n",
    "os.mkdir(test_path)\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    \n",
    "    all_imgs = os.listdir(os.path.join(base_path, classes[i]))\n",
    "    all_imgs = [f for f in all_imgs if not f.startswith('.')]\n",
    "    random.seed(1)\n",
    "    random.shuffle(all_imgs)\n",
    "    \n",
    "    train_imgs = all_imgs[:800]\n",
    "    test_imgs = all_imgs[800:]\n",
    "    \n",
    "    # Copy each classes' images to train directory\n",
    "    for j in range(len(train_imgs)):\n",
    "        original_path = os.path.join(os.path.join(base_path, classes[i]), train_imgs[j])\n",
    "        new_path = os.path.join(train_path, train_imgs[j])\n",
    "        copyfile(original_path, new_path)\n",
    "    \n",
    "    # Copy each classes' images to test directory\n",
    "    for j in range(len(test_imgs)):\n",
    "        original_path = os.path.join(os.path.join(base_path, classes[i]), test_imgs[j])\n",
    "        new_path = os.path.join(test_path, test_imgs[j])\n",
    "        copyfile(original_path, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of training images: ', len(os.listdir(train_path))) # subtract one because there is one hidden file named '.DS_Store'\n",
    "print('number of test images: ', len(os.listdir(test_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected number of training images and validation images should be 3x800 -> 2400 and 3x200 -> 600.\n",
    "\n",
    "However, there might be some overlap images which appear in two or three classes simultaneously. For instance, an image might be a person walking on the street and there are several cars in the street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [label_name_person, label_name_phone, label_name_car]\n",
    "\n",
    "train_df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "\n",
    "# Find boxes in each image and put them in a dataframe\n",
    "train_imgs = os.listdir(train_path)\n",
    "train_imgs = [name for name in train_imgs if not name.startswith('.')]\n",
    "\n",
    "for i in range(len(train_imgs)):\n",
    "    sys.stdout.write('Parse train_imgs ' + str(i) + '; Number of boxes: ' + str(len(train_df)) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "    img_name = train_imgs[i]\n",
    "    img_id = img_name[0:16]\n",
    "    tmp_df = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "    for index, row in tmp_df.iterrows():\n",
    "        labelName = row['LabelName']\n",
    "        for i in range(len(label_names)):\n",
    "            if labelName == label_names[i]:\n",
    "                train_df = train_df.append({'FileName': img_name, \n",
    "                                            'XMin': row['XMin'], \n",
    "                                            'XMax': row['XMax'], \n",
    "                                            'YMin': row['YMin'], \n",
    "                                            'YMax': row['YMax'], \n",
    "                                            'ClassName': classes[i]}, \n",
    "                                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "\n",
    "# Find boxes in each image and put them in a dataframe\n",
    "test_imgs = os.listdir(test_path)\n",
    "test_imgs = [name for name in test_imgs if not name.startswith('.')]\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    sys.stdout.write('Parse test_imgs ' + str(i) + '; Number of boxes: ' + str(len(test_df)) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "    img_name = test_imgs[i]\n",
    "    img_id = img_name[0:16]\n",
    "    tmp_df = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "    for index, row in tmp_df.iterrows():\n",
    "        labelName = row['LabelName']\n",
    "        for i in range(len(label_names)):\n",
    "            if labelName == label_names[i]:\n",
    "                val_df = val_df.append({'FileName': img_name, \n",
    "                                            'XMin': row['XMin'], \n",
    "                                            'XMax': row['XMax'], \n",
    "                                            'YMin': row['YMin'], \n",
    "                                            'YMax': row['YMax'], \n",
    "                                            'ClassName': classes[i]}, \n",
    "                                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(base_path, 'train.csv'))\n",
    "test_df.to_csv(os.path.join(base_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write train.csv to annotation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(train_df.head())\n",
    "train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "\n",
    "# For training\n",
    "f= open(base_path + \"/annotation.txt\",\"w+\")\n",
    "for idx, row in train_df.iterrows():\n",
    "#     sys.stdout.write(str(idx) + '\\r')\n",
    "#     sys.stdout.flush()\n",
    "    img = cv2.imread((base_path + '/train/' + row['FileName']))\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    google_colab_file_path = 'drive/My Drive/AI/Dataset/Open Images Dataset v4 (Bounding Boxes)/train'\n",
    "    fileName = os.path.join(google_colab_file_path, row['FileName'])\n",
    "    className = row['ClassName']\n",
    "    f.write(fileName + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.head())\n",
    "test_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "\n",
    "# For test\n",
    "f= open(base_path + \"/test_annotation.txt\",\"w+\")\n",
    "for idx, row in test_df.iterrows():\n",
    "    sys.stdout.write(str(idx) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "    img = cv2.imread((base_path + '/test/' + row['FileName']))\n",
    "    height, width = img.shape[:2]\n",
    "    x1 = int(row['XMin'] * width)\n",
    "    x2 = int(row['XMax'] * width)\n",
    "    y1 = int(row['YMin'] * height)\n",
    "    y2 = int(row['YMax'] * height)\n",
    "    \n",
    "    google_colab_file_path = 'drive/My Drive/AI/Dataset/Open Images Dataset v4 (Bounding Boxes)/test'\n",
    "    fileName = os.path.join(google_colab_file_path, row['FileName'])\n",
    "    className = row['ClassName']\n",
    "    f.write(fileName + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
